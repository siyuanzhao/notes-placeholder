I keep a list of papers on memory networks, attention reading and reasoning.

*** Memory
- [[http://arxiv.org/abs/1410.3916][Memory Network]]
- [[http://arxiv.org/abs/1503.08895][End-To-End Memory Networks]]
- [[http://arxiv.org/abs/1502.05698][Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks]]
- [[http://arxiv.org/abs/1506.07285][Ask Me Anything: Dynamic Memory Networks for Natural Language Processing]]
- [[https://arxiv.org/abs/1606.03126][Key-Value Memory Networks for Directly Reading Documents]]
- [[https://arxiv.org/abs/1410.5401][Neural Turing Machines]]
- [[http://arxiv.org/abs/1607.00036][Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes]]
- [[http://arxiv.org/pdf/1505.00521.pdf][Reinforcement Learning Neural Turning Machines]]
- [[http://www.large-scale-sports-analytics.org/Large-Scale-Sports-Analytics/Submissions_files/paperID20.pdf][Learning Long-term Planning in Basketball Using Hierarchical Memory Networks]]  

*** Attention Reading
- [[https://arxiv.org/abs/1409.0473][Neural Machine Translation by Jointly Learning to Align and Translate]]
- [[http://arxiv.org/abs/1506.03340][Teaching Machines to Read and Comprehend]]
- [[https://arxiv.org/abs/1606.01549][Gated-Attention Readers for Text Comprehension]]
- [[http://arxiv.org/abs/1606.02245][Iterative Alternating Neural Attention for Machine Reading]]
- [[https://arxiv.org/abs/1607.04423][Attention-over-Attention Neural Networks for Reading Comprehension]]
- [[https://arxiv.org/abs/1511.02301][The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations]]


*** Reasoning
- [[http://arxiv.org/abs/1508.05508][Towards Neural Network-based Reasoning]]
- [[http://arxiv.org/pdf/1608.06349v1.pdf][Five Dimensions of Reasoning in the Wild]]
  
*** Two interesting papers from NLP
- [[http://www.emnlp2016.net/accepted-papers.html][All accepted papers]]
- [[https://arxiv.org/abs/1604.00727][Character-Level Question Answering with Attention]]
- [[http://arxiv.org/abs/1608.05604][Modeling Human Reading with Neural Attention]]

*** interesting papers from NIPS 2016
- [[https://nips.cc/Conferences/2016/AcceptedPapers][all accepted papers]]
- [[http://arxiv.org/abs/1608.05745][RETAIN: Interpretable Predictive Model in Healthcare using Reverse Time Attention Mechanism]]
- [[https://arxiv.org/abs/1606.05374][Avoiding Imposters and Delinquents: Adversarial Crowdsourcing and Peer Prediction]]
- [[http://arxiv.org/abs/1608.07328][Fundamental Limits of Budget-Fidelity Trade-off in Label Crowdsourcing]]

*** NLP
- [[http://arxiv.org/abs/1604.06045][Dialog-based Language Learning]]

*** Crowdsourcing
- [[http://arxiv.org/abs/1502.05696v3][Approval Voting and Incentives in Crowdsourcing]]
- [[https://arxiv.org/abs/1602.03481][Reliable Crowdsourcing under the Generalized Dawid-Skene Model]]


- [[http://www.psy.vanderbilt.edu/students/fougnidl/Fougnie-chap1.pdf][The Relationship between Attention and Working Memory]]
