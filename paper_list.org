I keep a list of papers on memory networks, attention reading and reasoning.

*** Memory
- [[http://arxiv.org/abs/1410.3916][Memory Network]]
- [[http://arxiv.org/abs/1503.08895][End-To-End Memory Networks]]
- [[http://arxiv.org/abs/1502.05698][Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks]]
- [[http://arxiv.org/abs/1506.07285][Ask Me Anything: Dynamic Memory Networks for Natural Language Processing]]
- [[https://arxiv.org/abs/1606.03126][Key-Value Memory Networks for Directly Reading Documents]]
- [[https://arxiv.org/abs/1410.5401][Neural Turing Machines]]
- [[http://arxiv.org/abs/1607.00036][Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes]]
- [[http://arxiv.org/pdf/1505.00521.pdf][Reinforcement Learning Neural Turning Machines]]
- [[http://www.large-scale-sports-analytics.org/Large-Scale-Sports-Analytics/Submissions_files/paperID20.pdf][Learning Long-term Planning in Basketball Using Hierarchical Memory Networks]]  
- [[https://arxiv.org/abs/1603.01417][Dynamic Memory Networks for Visual and Textual Question Answering]]
- [[http://www.nature.com/articles/nature20101.epdf?author_access_token%3DImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz][Hybrid computing using a neural network with dynamic external memory]]

*** Attention Reading
- [[https://arxiv.org/abs/1409.0473][Neural Machine Translation by Jointly Learning to Align and Translate]]
- [[http://arxiv.org/abs/1506.03340][Teaching Machines to Read and Comprehend]]
- [[https://arxiv.org/abs/1606.01549][Gated-Attention Readers for Text Comprehension]]
- [[http://arxiv.org/abs/1606.02245][Iterative Alternating Neural Attention for Machine Reading]]
- [[https://arxiv.org/abs/1607.04423][Attention-over-Attention Neural Networks for Reading Comprehension]]
- [[https://arxiv.org/abs/1511.02301][The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations]]
- [[https://www.aclweb.org/anthology/W/W16/W16-0103.pdf][Attention-Based Convolutional Neural Network for Machine Comprehension]]

*** Reasoning
- [[http://arxiv.org/abs/1508.05508][Towards Neural Network-based Reasoning]]
- [[http://arxiv.org/pdf/1608.06349v1.pdf][Five Dimensions of Reasoning in the Wild]]
- [[https://arxiv.org/abs/1607.01426][Chains of Reasoning over Entities, Relations, and Text using Recurrent Neural Networks]]
  
*** Two interesting papers from EMNLP
- [[http://www.emnlp2016.net/accepted-papers.html][All accepted papers]]
- [[https://arxiv.org/abs/1604.00727][Character-Level Question Answering with Attention]]
- [[http://arxiv.org/abs/1608.05604][Modeling Human Reading with Neural Attention]]
  
*** interesting papers from NIPS 2016
- [[https://nips.cc/Conferences/2016/AcceptedPapers][all accepted papers]]
- [[http://arxiv.org/abs/1608.05745][RETAIN: Interpretable Predictive Model in Healthcare using Reverse Time Attention Mechanism]]
- [[https://arxiv.org/abs/1606.05374][Avoiding Imposters and Delinquents: Adversarial Crowdsourcing and Peer Prediction]]
- [[http://arxiv.org/abs/1608.07328][Fundamental Limits of Budget-Fidelity Trade-off in Label Crowdsourcing]]
- [[http://arxiv.org/abs/1604.06045][Dialog-based Language Learning]]


*** Crowdsourcing
- [[http://arxiv.org/abs/1502.05696v3][Approval Voting and Incentives in Crowdsourcing]]
- [[https://arxiv.org/abs/1602.03481][Reliable Crowdsourcing under the Generalized Dawid-Skene Model]]


- [[http://www.psy.vanderbilt.edu/students/fougnidl/Fougnie-chap1.pdf][The Relationship between Attention and Working Memory]]

*** Random papers
- [[https://arxiv.org/abs/1203.2990][Evolving Culture vs Local Minima]]

*** Semi-supervised learning
- [[https://arxiv.org/abs/1507.02672][Semi-Supervised Learning with Ladder Networks]]
